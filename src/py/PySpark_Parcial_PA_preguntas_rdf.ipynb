{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac0b06f",
   "metadata": {},
   "source": [
    "# Parcial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d63251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1746314465559_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-12-175.ec2.internal:20888/proxy/application_1746314465559_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-15-170.ec2.internal:8042/node/containerlogs/container_1746314465559_0001_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d9e8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1746314465559_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-12-175.ec2.internal:20888/proxy/application_1746314465559_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-15-170.ec2.internal:8042/node/containerlogs/container_1746314465559_0001_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "          \"spark.pyspark.python\": \"python\",\n",
    "          \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "          \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "          \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cd1b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>2</td><td>application_1746314465559_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-12-175.ec2.internal:20888/proxy/application_1746314465559_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-4-239.ec2.internal:8042/node/containerlogs/container_1746314465559_0003_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spark\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Tipos de datos\n",
    "from pyspark.sql.types import (\n",
    "    StringType, FloatType, IntegerType, DateType, StructType, StructField\n",
    ")\n",
    "\n",
    "# Funciones de PySpark\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, lower, trim, regexp_replace, udf\n",
    ")\n",
    "\n",
    "# Otros\n",
    "import unicodedata\n",
    "from functools import reduce\n",
    "import re\n",
    "\n",
    "from pyspark.sql.functions import countDistinct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d896bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Profeco Parte A\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7dcfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f43724a58d4e1695cc04297485e181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bucket\n",
    "NAME = 'thmrudolf' ##CAMBIAR AQUÍ SU NOMBRE.\n",
    "BUCKET = f\"s3://itam-analytics-{NAME}\"\n",
    "FOLDER = 'profeco'\n",
    "\n",
    "\n",
    "# type of catalog\n",
    "CATALOG_TYPE = 'basicos'\n",
    "\n",
    "s3_path_parquet = f\"{BUCKET}/{FOLDER}/parquet/\"\n",
    "df = spark.read.parquet(s3_path_parquet)\n",
    "df.printSchema()\n",
    "df.select(\"anio\", \"catalogo\", \"estado\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887998fc",
   "metadata": {},
   "source": [
    "## Parte A\n",
    "En esta parte necesitarán levantar un cluster en AWS con Hadoop y Pyspark (Como lo hicimos en clase). Solo necesitan 1 cluster por equipo.\n",
    "\n",
    "El nombre de tu cluster debe ser cluster_ + la mátricula (número de estudiante) más chica de los miembros del equipo. Por ejemplo: cluster_54903.\n",
    "ETL con el Cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f34c8d",
   "metadata": {},
   "source": [
    "Contesta las siguientes preguntas utilizando PySpark. Realiza el siguiente análisis (por año) y sobre todos los catálogos.\n",
    "\n",
    "¿Cuántos catálogos diferentes tenemos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d090fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_catalogos = df.select(\"catalogo\").distinct().count()\n",
    "print(f\"Total de catálogos distintos: {num_catalogos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23043369",
   "metadata": {},
   "source": [
    "¿Cuáles son los 20 catálogos con más observaciones? Guarda la salida de este query en tu bucket de S3, lo necesitaremos más adelante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_catalogos = df.groupBy(\"catalogo\").count().orderBy(col(\"count\").desc()).limit(20)\n",
    "\n",
    "# Mostrar resultados\n",
    "top_catalogos.show()\n",
    "\n",
    "# Guardar la salida en S3\n",
    "s3_path_top_20 = f\"{BUCKET}/{FOLDER}/top_20_catalogos/\"\n",
    "top_catalogos.write.mode(\"overwrite\").parquet(s3_path_top_20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de624abe",
   "metadata": {},
   "source": [
    "¿Tenemos datos de todos los estados del país? De no ser así, ¿cuáles faltan?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener lista de estados únicos en los datos\n",
    "estados_en_datos = df.select(col(\"estado\")).distinct()\n",
    "estados_en_datos.show(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b72c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "estados_mexico = [\n",
    "    \"aguascalientes\", \"baja california\", \"baja california sur\", \"campeche\", \"coahuila de zaragoza\",\n",
    "    \"colima\", \"chiapas\", \"chihuahua\", \"durango\", \"guanajuato\", \"guerrero\", \"hidalgo\",\n",
    "    \"jalisco\", \"ciudad de mexico\", \"estado de mexico\", \"michoacan de ocampo\", \"morelos\", \"nayarit\", \"nuevo leon\", \"oaxaca\",\n",
    "    \"puebla\", \"queretaro\", \"quintana roo\", \"san luis potosi\", \"sinaloa\", \"sonora\",\n",
    "    \"tabasco\", \"tamaulipas\", \"tlaxcala\", \"veracruz\", \"yucatan\", \"zacatecas\"\n",
    "]\n",
    "\n",
    "# Convertir PySpark DataFrame a lista para comparación\n",
    "estados_en_datos_lista = [row.estado for row in estados_en_datos.collect()]\n",
    "\n",
    "# Encontrar estados faltantes\n",
    "estados_faltantes = list(set(estados_mexico) - set(estados_en_datos_lista))\n",
    "\n",
    "print(f\"Estados faltantes en los datos: {estados_faltantes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a0b60",
   "metadata": {},
   "source": [
    "¿Cuántas observaciones tenemos por estado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Contar catálogos distintos por estado y año\n",
    "catalogos_por_estado_anio = df.groupBy(\"estado\", \"anio\") \\\n",
    "    .agg(countDistinct(\"catalogo\").alias(\"num_catalogos\"))\n",
    "\n",
    "# Mostrar resultados\n",
    "catalogos_por_estado_anio.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d1971",
   "metadata": {},
   "source": [
    "De cada estado obten: el número de catalogos diferentes por año, ¿ha aumentado el número de catálogos con el tiempo?\n",
    "Utilizando Spark contesta las siguientes preguntas a partir del catálogo que le tocó a tu equipo. Recuerda trabajar en el archivo con los datos particionados de otra manera tus queries van a tardar mucho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Obtener el número de catálogos distintos por estado y año\n",
    "df_catalogos_por_estado_anio = df.groupBy(\"estado\", \"anio\").agg(countDistinct(\"catalogo\").alias(\"num_catalogos\"))\n",
    "\n",
    "# Mostrar resultados\n",
    "df_catalogos_por_estado_anio.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "# Definir ventana por estado para comparar años anteriores\n",
    "window_spec = Window.partitionBy(\"estado\").orderBy(\"anio\")\n",
    "\n",
    "# Calcular la diferencia de catálogos con el año anterior\n",
    "catalogos_por_estado_anio = catalogos_por_estado_anio.withColumn(\n",
    "    \"diferencia_anual\",\n",
    "    col(\"num_catalogos\") - lag(\"num_catalogos\", 1).over(window_spec)\n",
    ")\n",
    "\n",
    "catalogos_por_estado_anio.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los resultados en S3 para su posterior análisis\n",
    "\n",
    "s3_path_estado_anio = f\"{BUCKET}/{FOLDER}/catalogos_por_estado_anio/\"\n",
    "df_catalogos_por_estado_anio.write.mode(\"overwrite\").parquet(s3_path_estado_anio)\n",
    "\n",
    "print(f\"Los resultados se han guardado en: {s3_path_estado_anio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddd365",
   "metadata": {},
   "source": [
    "¿Cuańtas marcas diferentes tiene tu categoría?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f180d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7726c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogo_objetivo = \"basicos\"\n",
    "df_filtered = df.filter(df[\"catalogo\"] == catalogo_objetivo)\n",
    "\n",
    "\n",
    "# Contar marcas distintas por categoría\n",
    "num_marcas = df_filtered.select(countDistinct(\"marca\").alias(\"num_marcas\")).withColumn(\"catalogo\", lit(catalogo_objetivo))\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar resultados\n",
    "\n",
    "num_marcas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deff60a",
   "metadata": {},
   "source": [
    "¿Cuál es la marca con mayor precio? ¿En qué estado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b151895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_precio = df.orderBy(col(\"precio\").desc()).limit(1)#.withColumn(\"catalogo\", lit(catalogo_objetivo))\n",
    "df_max_precio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf8e59",
   "metadata": {},
   "source": [
    "¿Cuál es la marca con menor precio en CDMX? (en aquel entonces Distrito Federal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fb447",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df.select(\"estado\").distinct().collect()\n",
    "for row in unique_values:\n",
    "    print(row[\"estado\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6643e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdmx = df.filter(df['estado'] == 'ciudad de mexico')\n",
    "\n",
    "df_cdmx_menor_precio_cdmx = df_cdmx.orderBy(col(\"precio\").asc()).limit(1)\n",
    "df_cdmx_menor_precio_cdmx.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c0b23",
   "metadata": {},
   "source": [
    "¿Cuál es la marca con mayores observaciones?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_by_cat = df.filter(df['catalogo']=='basicos')\n",
    "df_producto_mas_frecuente = df_filtered_by_cat.groupBy(\"producto\").count().orderBy(col(\"count\").desc()).limit(1)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_producto_mas_frecuente.show()\n",
    "\n",
    "df_marca_mas_frecuente = df_filtered_by_cat.groupBy(\"marca\").count().orderBy(col(\"count\").desc()).limit(1)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_marca_mas_frecuente.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d77643",
   "metadata": {},
   "source": [
    "¿Cuáles son el top 5 de marcas con mayor precio en cada estado? ¿Son diferentes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, row_number\n",
    "#Calcular el precio máximo por marca y estado\n",
    "df_precio_por_marca_estado = df.groupBy(\"estado\", \"marca\", \"precio\").agg(col(\"precio\").alias(\"max_precio\"))\n",
    "\n",
    "# Aplicar ventana para obtener el top 5 de marcas con mayor precio por estado\n",
    "window_spec = Window.partitionBy(\"estado\").orderBy(col(\"max_precio\").desc())\n",
    "df_top5 = df_precio_por_marca_estado.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_top5.select(\"estado\", \"marca\", \"max_precio\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27a77e",
   "metadata": {},
   "source": [
    "¿Cuáles son el top 5 de marcas con menor precio en CDMX? (en aquel entonces Distrito Federal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular el precio máximo por marca y estado\n",
    "df_cdmx = df.filter(df['estado']=='ciudad de mexico')\n",
    "window_spec = Window.orderBy(col(\"precio\").asc())\n",
    "df_top5_cdmx = df_cdmx.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_top5_cdmx.select(\"producto\", \"estado\", \"precio\").show()\n",
    "df_top5_cdmx.select(\"marca\", \"estado\", \"precio\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21610188",
   "metadata": {},
   "source": [
    "¿Cuáles son el top 5 de marcas con mayores observaciones? ¿Se parecen a las de nivel por estado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el conteo de observaciones por marca\n",
    "df_top5_global = df.groupBy(\"marca\").count().orderBy(col(\"count\").desc()).limit(5)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_top5_global.show()\n",
    "\n",
    "# Obtener el conteo de observaciones por marca\n",
    "df_top5_global_p = df.groupBy(\"producto\").count().orderBy(col(\"count\").desc()).limit(5)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_top5_global_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar ventana para obtener el top 5 de cada estado (marca)\n",
    "window_spec = Window.partitionBy(\"estado\").orderBy(col(\"count\").desc())\n",
    "\n",
    "df_top5_estado = df.groupBy(\"estado\", \"marca\").count() \\\n",
    "    .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_top5_estado.show()\n",
    "\n",
    "# Aplicar ventana para obtener el top 5 de cada estado (producto)\n",
    "df_top5_estado_p = df.groupBy(\"estado\", \"producto\").count() \\\n",
    "    .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_top5_estado_p.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f78b4b",
   "metadata": {},
   "source": [
    " ¿Se parecen a las de nivel por estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "# Obtener lista de marcas en el top global\n",
    "marcas_top_global = [row[\"marca\"] for row in df_top5_global.collect()]\n",
    "\n",
    "# Agrupar marcas del top 5 por estado y compararlas con el top global\n",
    "df_comparacion = df_top5_estado.groupBy(\"estado\").agg(collect_list(\"marca\").alias(\"top_5_marcas\"))\n",
    "\n",
    "df_comparacion.show(truncate=False)\n",
    "\n",
    "# Obtener lista de marcas en el top global\n",
    "producto_top_global = [row[\"producto\"] for row in df_top5_global_p.collect()]\n",
    "\n",
    "# Agrupar marcas del top 5 por estado y compararlas con el top global\n",
    "df_comparacion_p = df_top5_estado_p.groupBy(\"estado\").agg(collect_list(\"producto\").alias(\"top_5_productos\"))\n",
    "\n",
    "df_comparacion.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0b628",
   "metadata": {},
   "source": [
    "¿Ha dejado de existir alguna marca durante los años que tienes? ¿Cuál? ¿Cuándo desapareció?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener marcas únicas por año\n",
    "df_marcas_por_anio = df.select(\"anio\", \"marca\").distinct()\n",
    "\n",
    "# Obtener todas las marcas que existieron alguna vez\n",
    "marcas_existentes = df_marcas_por_anio.select(\"marca\").distinct()\n",
    "\n",
    "# Obtener la última aparición de cada marca\n",
    "df_ultima_aparicion = df_marcas_por_anio.groupBy(\"marca\").agg({\"anio\": \"max\"}).withColumnRenamed(\"max(anio)\", \"ultimo_anio\")\n",
    "\n",
    "# Comparar con las marcas actuales (último año presente en los datos)\n",
    "ultimo_anio = df.select(\"anio\").distinct().orderBy(\"anio\", ascending=False).limit(1).collect()[0][\"anio\"]\n",
    "df_marcas_desaparecidas = df_ultima_aparicion.filter(df_ultima_aparicion[\"ultimo_anio\"] < ultimo_anio)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_marcas_desaparecidas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1af69",
   "metadata": {},
   "source": [
    "Genera una gráfica de serie de tiempo por estado para la marca con mayor precio -en todos los años-, donde el eje equis es el año y el eje ye es el precio máximo.\n",
    "Nota: Recuerden descargar del cluster su análisis en Jupyter, de otra manera se borrará.\n",
    "\n",
    "Hint: Guarda tus consultas en archivos que puedas guardar en S3 y luego leer desde Pandas o RStudio, para hacer tus gráficas o cuadros compartivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._sc.install_pypi_package(\"matplotlib\", \"https://pypi.org/simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Inicializar Spark Session\n",
    "spark = SparkSession.builder.appName(\"Time Series Analysis\").getOrCreate()\n",
    "\n",
    "# Cargar datos desde S3\n",
    "df = spark.read.parquet(\"s3a://tu-bucket/datos.parquet\")\n",
    "\n",
    "# Obtener la marca con el mayor precio en todos los años\n",
    "df_max_precio_marca = df.groupBy(\"estado\", \"anio\", \"marca\").agg(col(\"precio\").alias(\"max_precio\")) \\\n",
    "    .orderBy(col(\"max_precio\").desc()).dropDuplicates([\"anio\", \"estado\"])\n",
    "\n",
    "# Convertir a Pandas para graficar\n",
    "df_pandas = df_max_precio_marca.toPandas()\n",
    "\n",
    "# Crear gráfica de serie de tiempo\n",
    "plt.figure(figsize=(12, 6))\n",
    "for estado in df_pandas[\"estado\"].unique():\n",
    "    data_estado = df_pandas[df_pandas[\"estado\"] == estado]\n",
    "    plt.plot(data_estado[\"anio\"], data_estado[\"max_precio\"], marker=\"o\", label=estado)\n",
    "\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Precio Máximo\")\n",
    "plt.title(\"Evolución del Precio Máximo por Estado (Marca Más Cara)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f89a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa96f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
