{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac0b06f",
   "metadata": {},
   "source": [
    "# Parcial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d63251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9e8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuración de Spark para habilitar el uso de un entorno virtual de Python\n",
    "# Esta configuración asegura que PySpark utilice un entorno virtual específico para ejecutar el código.\n",
    "# Se especifica el intérprete de Python, se habilita el uso de entornos virtuales y se define el tipo y la ruta del entorno virtual.\n",
    "\n",
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "          \"spark.pyspark.python\": \"python\",  # Especifica el intérprete de Python\n",
    "          \"spark.pyspark.virtualenv.enabled\": \"true\",  # Habilita el uso de entornos virtuales\n",
    "          \"spark.pyspark.virtualenv.type\":\"native\",  # Define el tipo de entorno virtual (nativo)\n",
    "          \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"  # Ruta al ejecutable de virtualenv\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd1b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1746393038637_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-5-244.ec2.internal:20888/proxy/application_1746393038637_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-6-82.ec2.internal:8042/node/containerlogs/container_1746393038637_0002_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importación de módulos y funciones necesarias para trabajar con PySpark y otras utilidades\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql import SparkSession, DataFrame  # Para crear y manejar sesiones de Spark y DataFrames\n",
    "from pyspark.sql.window import Window  # Para realizar operaciones de ventana en PySpark\n",
    "\n",
    "# Tipos de datos\n",
    "from pyspark.sql.types import (  # Para definir esquemas y tipos de datos en PySpark\n",
    "    StringType, FloatType, IntegerType, DateType, StructType, StructField\n",
    ")\n",
    "\n",
    "# Funciones de PySpark\n",
    "from pyspark.sql.functions import (  # Funciones comunes para manipulación de datos en PySpark\n",
    "    col, lit, lower, trim, regexp_replace, udf\n",
    ")\n",
    "\n",
    "# Otros\n",
    "import unicodedata  # Para normalización de texto (e.g., eliminar acentos)\n",
    "from functools import reduce  # Para aplicar funciones acumulativas\n",
    "import re  # Para trabajar con expresiones regulares\n",
    "\n",
    "from pyspark.sql.functions import countDistinct  # Para contar valores distintos en una columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d896bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear una sesión de Spark\n",
    "# Esta configuración inicializa una sesión de Spark con el nombre \"Profeco Parte A\".\n",
    "# La sesión de Spark es necesaria para ejecutar operaciones distribuidas en PySpark.\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Profeco Parte A\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7dcfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- producto: string (nullable = true)\n",
      " |-- marca: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- precio: float (nullable = true)\n",
      " |-- fecha: date (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- ciudad: string (nullable = true)\n",
      " |-- catalogo: string (nullable = true)\n",
      " |-- anio: integer (nullable = true)\n",
      "\n",
      "+----+--------+--------------+\n",
      "|anio|catalogo|        estado|\n",
      "+----+--------+--------------+\n",
      "|2023| basicos|aguascalientes|\n",
      "|2023| basicos|aguascalientes|\n",
      "|2023| basicos|aguascalientes|\n",
      "|2023| basicos|aguascalientes|\n",
      "|2023| basicos|aguascalientes|\n",
      "+----+--------+--------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Configuración de variables y carga de datos desde S3\n",
    "\n",
    "# Nombre del bucket en S3 (modificar según el nombre del usuario)\n",
    "NAME = 'thmrudolf'  # CAMBIAR AQUÍ SU NOMBRE.\n",
    "BUCKET = f\"s3://itam-analytics-{NAME}\"  # Ruta del bucket en S3\n",
    "FOLDER = 'profeco'  # Carpeta dentro del bucket\n",
    "\n",
    "# Tipo de catálogo a analizar\n",
    "CATALOG_TYPE = 'basicos'\n",
    "\n",
    "# Ruta de los archivos Parquet en S3\n",
    "s3_path_parquet = f\"{BUCKET}/{FOLDER}/parquet/\"\n",
    "\n",
    "# Cargar los datos desde los archivos Parquet en S3\n",
    "df = spark.read.parquet(s3_path_parquet)\n",
    "\n",
    "# Mostrar el esquema del DataFrame cargado\n",
    "df.printSchema()\n",
    "\n",
    "# Mostrar las primeras 5 filas de las columnas \"anio\", \"catalogo\" y \"estado\"\n",
    "df.select(\"anio\", \"catalogo\", \"estado\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887998fc",
   "metadata": {},
   "source": [
    "## Parte A\n",
    "En esta parte necesitarán levantar un cluster en AWS con Hadoop y Pyspark (Como lo hicimos en clase). Solo necesitan 1 cluster por equipo.\n",
    "\n",
    "El nombre de tu cluster debe ser cluster_ + la mátricula (número de estudiante) más chica de los miembros del equipo. Por ejemplo: cluster_54903.\n",
    "ETL con el Cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f34c8d",
   "metadata": {},
   "source": [
    "Contesta las siguientes preguntas utilizando PySpark. Realiza el siguiente análisis (por año) y sobre todos los catálogos.\n",
    "\n",
    "¿Cuántos catálogos diferentes tenemos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d090fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de cat?logos distintos: 12"
     ]
    }
   ],
   "source": [
    "# Contar el número total de catálogos distintos en el DataFrame\n",
    "# Utilizamos la función `distinct()` para obtener los valores únicos de la columna \"catalogo\"\n",
    "# y luego aplicamos `count()` para contar cuántos valores únicos hay.\n",
    "\n",
    "num_catalogos = df.select(\"catalogo\").distinct().count()\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"Total de catálogos distintos: {num_catalogos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72256e8e",
   "metadata": {},
   "source": [
    "Respuesta: En total contamos con 12 catalógos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23043369",
   "metadata": {},
   "source": [
    "¿Cuáles son los 20 catálogos con más observaciones? Guarda la salida de este query en tu bucket de S3, lo necesitaremos más adelante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada5e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|           catalogo|   count|\n",
      "+-------------------+--------+\n",
      "|            basicos|46965358|\n",
      "|       medicamentos|19207468|\n",
      "|  electrodomesticos| 7175494|\n",
      "| frutas y legumbres| 5041527|\n",
      "|   utiles escolares| 2936010|\n",
      "|           mercados| 2238608|\n",
      "|           juguetes| 1432183|\n",
      "|              pacic| 1079162|\n",
      "|pescados y mariscos|  569519|\n",
      "|          navidenos|  236543|\n",
      "|              tenis|   15768|\n",
      "|        aeropuertos|     581|\n",
      "+-------------------+--------+"
     ]
    }
   ],
   "source": [
    "# Obtener los 20 catálogos con más observaciones\n",
    "# Agrupamos los datos por la columna \"catalogo\" y contamos el número de observaciones por catálogo.\n",
    "# Luego, ordenamos los resultados en orden descendente por el conteo y seleccionamos los 20 primeros.\n",
    "\n",
    "top_catalogos = df.groupBy(\"catalogo\").count().orderBy(col(\"count\").desc()).limit(20)\n",
    "\n",
    "# Mostrar los resultados en la consola\n",
    "top_catalogos.show()\n",
    "\n",
    "# Guardar los resultados en S3\n",
    "# Los resultados se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "s3_path_top_20 = f\"{BUCKET}/{FOLDER}/top_20_catalogos/\"\n",
    "top_catalogos.write.mode(\"overwrite\").parquet(s3_path_top_20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac21312",
   "metadata": {},
   "source": [
    "**Respuesta:** En total contamos con 12 catalógos como resulto en la pregunta anterior, se muestra los 12 catalogos en la tabla arriba. El con mas observaciones es el *basico* el con menos *aeropuertos*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de624abe",
   "metadata": {},
   "source": [
    "¿Tenemos datos de todos los estados del país? De no ser así, ¿cuáles faltan?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95777a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              estado|\n",
      "+--------------------+\n",
      "|          tamaulipas|\n",
      "|           zacatecas|\n",
      "|          nuevo leon|\n",
      "|            campeche|\n",
      "|     san luis potosi|\n",
      "|            veracruz|\n",
      "|             morelos|\n",
      "|          guanajuato|\n",
      "|              sonora|\n",
      "|            tlaxcala|\n",
      "|             nayarit|\n",
      "|             sinaloa|\n",
      "|              oaxaca|\n",
      "|            guerrero|\n",
      "|        quintana roo|\n",
      "|           queretaro|\n",
      "|    estado de mexico|\n",
      "|              puebla|\n",
      "|             durango|\n",
      "|             jalisco|\n",
      "|      aguascalientes|\n",
      "|coahuila de zaragoza|\n",
      "| baja california sur|\n",
      "|              colima|\n",
      "|             tabasco|\n",
      "|           chihuahua|\n",
      "|     baja california|\n",
      "|    ciudad de mexico|\n",
      "|             yucatan|\n",
      "|             chiapas|\n",
      "|             hidalgo|\n",
      "| michoacan de ocampo|\n",
      "+--------------------+"
     ]
    }
   ],
   "source": [
    "# Obtener lista de estados únicos en los datos\n",
    "# Se selecciona la columna \"estado\" del DataFrame, se eliminan duplicados con `distinct()`\n",
    "# y se muestran los resultados (hasta 32 estados) en la consola.\n",
    "estados_en_datos = df.select(col(\"estado\")).distinct()\n",
    "estados_en_datos.show(32)\n",
    "\n",
    "# Guardar la lista de estados únicos en S3\n",
    "# Los datos se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "s3_path_estados = f\"{BUCKET}/{FOLDER}/estados/\"\n",
    "estados_en_datos.write.mode(\"overwrite\").parquet(s3_path_estados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb151c4",
   "metadata": {},
   "source": [
    "**Respuesta:** En un primer paso se analisa cuales son lo estados mencionados. Se ve en la lista arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b72c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estados faltantes en los datos: []"
     ]
    }
   ],
   "source": [
    "# Lista de estados de México\n",
    "# Esta lista contiene los nombres de los 32 estados de México, que se utilizarán para comparar con los datos disponibles.\n",
    "estados_mexico = [\n",
    "    \"aguascalientes\", \"baja california\", \"baja california sur\", \"campeche\", \"coahuila de zaragoza\",\n",
    "    \"colima\", \"chiapas\", \"chihuahua\", \"durango\", \"guanajuato\", \"guerrero\", \"hidalgo\",\n",
    "    \"jalisco\", \"ciudad de mexico\", \"estado de mexico\", \"michoacan de ocampo\", \"morelos\", \"nayarit\", \"nuevo leon\", \"oaxaca\",\n",
    "    \"puebla\", \"queretaro\", \"quintana roo\", \"san luis potosi\", \"sinaloa\", \"sonora\",\n",
    "    \"tabasco\", \"tamaulipas\", \"tlaxcala\", \"veracruz\", \"yucatan\", \"zacatecas\"\n",
    "]\n",
    "\n",
    "# Convertir PySpark DataFrame a lista para comparación\n",
    "# Se extraen los estados únicos presentes en los datos y se convierten en una lista de Python.\n",
    "estados_en_datos_lista = [row.estado for row in estados_en_datos.collect()]\n",
    "\n",
    "# Encontrar estados faltantes\n",
    "# Se calcula la diferencia entre la lista completa de estados de México y los estados presentes en los datos.\n",
    "# Esto permite identificar los estados que no están representados en el DataFrame.\n",
    "estados_faltantes = list(set(estados_mexico) - set(estados_en_datos_lista))\n",
    "\n",
    "# Imprimir los estados faltantes\n",
    "# Se muestra la lista de estados que no están presentes en los datos.\n",
    "print(f\"Estados faltantes en los datos: {estados_faltantes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e268e",
   "metadata": {},
   "source": [
    "En un segundo paso, se define una lista con todos estados de México y se compara esta lista con la lista que se encontro en los datos. Resulta que todos los estados están mencionados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a0b60",
   "metadata": {},
   "source": [
    "¿Cuántas observaciones tenemos por estado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342fbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-------------+\n",
      "|             estado|anio|num_catalogos|\n",
      "+-------------------+----+-------------+\n",
      "|     aguascalientes|2021|           10|\n",
      "|michoacan de ocampo|2020|            9|\n",
      "|             oaxaca|2020|            9|\n",
      "|            yucatan|2021|           10|\n",
      "|             sonora|2023|           11|\n",
      "|         nuevo leon|2023|           11|\n",
      "|michoacan de ocampo|2023|           11|\n",
      "|    baja california|2022|           11|\n",
      "|     aguascalientes|2019|           11|\n",
      "|           tlaxcala|2023|           11|\n",
      "|          queretaro|2020|            9|\n",
      "|          queretaro|2023|           11|\n",
      "|baja california sur|2018|            9|\n",
      "|            sinaloa|2021|            9|\n",
      "|   ciudad de mexico|2019|           10|\n",
      "|            hidalgo|2023|           11|\n",
      "|            tabasco|2024|            9|\n",
      "|           campeche|2023|           11|\n",
      "|baja california sur|2021|           10|\n",
      "|    baja california|2023|           11|\n",
      "+-------------------+----+-------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Obtener el número de catálogos distintos por estado y año\n",
    "# Agrupamos los datos por las columnas \"estado\" y \"anio\", y utilizamos la función `countDistinct`\n",
    "# para contar el número de catálogos únicos en cada combinación de estado y año.\n",
    "df_catalogos_por_estado_anio = df.groupBy(\"estado\", \"anio\").agg(countDistinct(\"catalogo\").alias(\"num_catalogos\"))\n",
    "\n",
    "# Mostrar resultados\n",
    "# Se imprimen los resultados en la consola para verificar el número de catálogos distintos por estado y año.\n",
    "df_catalogos_por_estado_anio.show()\n",
    "\n",
    "# Guardar la salida en S3\n",
    "# Los resultados se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "# Los datos se particionan por \"estado\" y \"anio\" para facilitar consultas posteriores.\n",
    "s3_path_obs_por_estado = f\"{BUCKET}/{FOLDER}/obs_por_estado_y_anio/\"\n",
    "df_catalogos_por_estado_anio.write.mode(\"overwrite\") \\\n",
    "                            .partitionBy(\"estado\", \"anio\") \\\n",
    "                            .option(\"compression\", \"snappy\") \\\n",
    "                            .parquet(s3_path_obs_por_estado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823b8e3",
   "metadata": {},
   "source": [
    "**Respuestas:** La tabla ilustra el nuemero de catalogos por estado y año. Se cuarda este informacion en un S3 as parquet para posible analisis futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0459d4",
   "metadata": {},
   "source": [
    "De cada estado obten: el número de catalogos diferentes por año, ¿ha aumentado el número de catálogos con el tiempo?\n",
    "Utilizando Spark contesta las siguientes preguntas a partir del catálogo que le tocó a tu equipo. Recuerda trabajar en el archivo con los datos particionados de otra manera tus queries van a tardar mucho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04ee54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+-------------+----------------+\n",
      "|         estado|anio|num_catalogos|diferencia_anual|\n",
      "+---------------+----+-------------+----------------+\n",
      "| aguascalientes|2018|            9|            NULL|\n",
      "| aguascalientes|2019|           11|               2|\n",
      "| aguascalientes|2020|            9|              -2|\n",
      "| aguascalientes|2021|           10|               1|\n",
      "| aguascalientes|2022|           11|               1|\n",
      "| aguascalientes|2023|           11|               0|\n",
      "| aguascalientes|2024|            9|              -2|\n",
      "|baja california|2018|           10|            NULL|\n",
      "|baja california|2019|           10|               0|\n",
      "|baja california|2020|            9|              -1|\n",
      "+---------------+----+-------------+----------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, col\n",
    "\n",
    "# Definir ventana por estado para comparar años anteriores\n",
    "# Se utiliza una ventana particionada por \"estado\" y ordenada por \"anio\".\n",
    "# Esto permite calcular métricas basadas en valores de años anteriores dentro de cada estado.\n",
    "window_spec = Window.partitionBy(\"estado\").orderBy(\"anio\")\n",
    "\n",
    "# Calcular la diferencia de catálogos con el año anterior\n",
    "# Se utiliza la función `lag` para obtener el valor de \"num_catalogos\" del año anterior.\n",
    "# Luego, se calcula la diferencia entre el número de catálogos del año actual y el año anterior.\n",
    "catalogos_por_estado_anio = df_catalogos_por_estado_anio.withColumn(\n",
    "    \"diferencia_anual\",\n",
    "    col(\"num_catalogos\") - lag(\"num_catalogos\", 1).over(window_spec)\n",
    ")\n",
    "\n",
    "# Mostrar los primeros 10 resultados\n",
    "# Se imprimen las primeras 10 filas del DataFrame resultante para verificar los cálculos.\n",
    "catalogos_por_estado_anio.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c1fe6",
   "metadata": {},
   "source": [
    "**Respuesta:** La tabla ilustra el numero de catalogos por año y estado. Hay poca variacion. Aguas Calientes por ejemplo tiene en promedio 10 catalogos. Hay que hacer una estadistica para cada estado (promedio, std) para ver que tanta variacion hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263636a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardar la salida en S3\n",
    "# Los resultados se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "# Los datos se particionan por \"estado\" y \"anio\" para facilitar consultas posteriores.\n",
    "s3_path_cat_dif_anio = f\"{BUCKET}/{FOLDER}/catalogos_distintos/\"\n",
    "catalogos_por_estado_anio.write.mode(\"overwrite\")\\\n",
    "                        .partitionBy(\"estado\", \"anio\")\\\n",
    "                        .option(\"compression\", \"snappy\") \\\n",
    "                        .parquet(s3_path_cat_dif_anio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611abf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los resultados se han guardado en: s3://itam-analytics-thmrudolf/profeco/catalogos_por_estado_anio/"
     ]
    }
   ],
   "source": [
    "# Guardar los resultados en S3 para su posterior análisis\n",
    "# Los datos se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "# Se particionan por \"estado\" y \"anio\" para facilitar consultas posteriores y se utiliza compresión Snappy.\n",
    "\n",
    "s3_path_estado_anio = f\"{BUCKET}/{FOLDER}/catalogos_por_estado_anio/\"\n",
    "df_catalogos_por_estado_anio.write.mode(\"overwrite\") \\\n",
    "                        .partitionBy(\"estado\", \"anio\") \\\n",
    "                        .option(\"compression\", \"snappy\") \\\n",
    "                        .parquet(s3_path_estado_anio)\n",
    "\n",
    "# Imprimir la ruta donde se guardaron los resultados\n",
    "print(f\"Los resultados se han guardado en: {s3_path_estado_anio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13655601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-------------+\n",
      "|             estado|anio|num_catalogos|\n",
      "+-------------------+----+-------------+\n",
      "|     aguascalientes|2021|           10|\n",
      "|michoacan de ocampo|2020|            9|\n",
      "|             oaxaca|2020|            9|\n",
      "|            yucatan|2021|           10|\n",
      "|             sonora|2023|           11|\n",
      "|         nuevo leon|2023|           11|\n",
      "|michoacan de ocampo|2023|           11|\n",
      "|    baja california|2022|           11|\n",
      "|     aguascalientes|2019|           11|\n",
      "|           tlaxcala|2023|           11|\n",
      "|          queretaro|2020|            9|\n",
      "|          queretaro|2023|           11|\n",
      "|baja california sur|2018|            9|\n",
      "|            sinaloa|2021|            9|\n",
      "|   ciudad de mexico|2019|           10|\n",
      "|            hidalgo|2023|           11|\n",
      "|            tabasco|2024|            9|\n",
      "|           campeche|2023|           11|\n",
      "|baja california sur|2021|           10|\n",
      "|    baja california|2023|           11|\n",
      "+-------------------+----+-------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_catalogos_por_estado_anio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddd365",
   "metadata": {},
   "source": [
    "¿Cuańtas marcas diferentes tiene tu categoría?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f180d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+--------------------+------+----------+--------------+--------------+--------+----+\n",
      "|            producto|           marca|                tipo|precio|     fecha|        estado|        ciudad|catalogo|anio|\n",
      "+--------------------+----------------+--------------------+------+----------+--------------+--------------+--------+----+\n",
      "|              aceite|           1-2-3|aceites y grasas ...|  56.9|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|              aceite|          canoil|aceites y grasas ...|  49.9|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|              aceite|         capullo|aceites y grasas ...|  73.9|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|              aceite|          mazola|aceites y grasas ...|  71.5|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|              aceite|        nutrioli|aceites y grasas ...|  49.5|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|              aceite|          oleico|aceites y grasas ...|  83.9|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|              aceite|       sabrosano|aceites y grasas ...|  45.5|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|     aceite de oliva|       carbonell|productos de temp...| 206.0|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|            aceituna|          bufalo|productos de temp...|  59.8|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|            aceituna|          bufalo|productos de temp...|  55.0|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|acondicionador y ...|head & shoulders|arts. para el cui...|  68.9|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|acondicionador y ...|         pantene|arts. para el cui...|  84.9|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|acondicionador y ...|         pantene|arts. para el cui...| 115.0|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|acondicionador y ...|           sedal|arts. para el cui...|  65.5|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|        agua con gas|      canada dry| refrescos envasados|  19.9|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|        agua con gas|            ciel| refrescos envasados|  22.5|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|        agua sin gas|        be-light| refrescos envasados|  17.5|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|        agua sin gas|        bonafont| refrescos envasados|  13.3|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|        agua sin gas|            ciel| refrescos envasados|  10.5|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "|        agua sin gas|            ciel| refrescos envasados|  13.6|2023-04-17|aguascalientes|aguascalientes| basicos|2023|\n",
      "+--------------------+----------------+--------------------+------+----------+--------------+--------------+--------+----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7726c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|num_marcas|catalogo|\n",
      "+----------+--------+\n",
      "|       637| basicos|\n",
      "+----------+--------+"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame por el catálogo objetivo\n",
    "# En este caso, se seleccionan únicamente las filas donde la columna \"catalogo\" tiene el valor \"basicos\".\n",
    "catalogo_objetivo = \"basicos\"\n",
    "df_filtered = df.filter(df[\"catalogo\"] == catalogo_objetivo)\n",
    "\n",
    "# Contar el número de marcas distintas en el catálogo objetivo\n",
    "# Se utiliza la función `countDistinct` para contar las marcas únicas en la columna \"marca\".\n",
    "# Además, se agrega una columna adicional \"catalogo\" para identificar el catálogo analizado.\n",
    "num_marcas = df_filtered.select(countDistinct(\"marca\").alias(\"num_marcas\")).withColumn(\"catalogo\", lit(catalogo_objetivo))\n",
    "\n",
    "# Mostrar los resultados en la consola\n",
    "# Se imprime el número de marcas distintas en el catálogo objetivo.\n",
    "num_marcas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c9d47",
   "metadata": {},
   "source": [
    "**Respuesta:** El catalogo *basico* tiene 637 marcas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deff60a",
   "metadata": {},
   "source": [
    "¿Cuál es la marca con mayor precio? ¿En qué estado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b151895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------------+--------+----------+------+------+-----------------+----+\n",
      "| producto|  marca|                tipo|  precio|     fecha|estado|ciudad|         catalogo|anio|\n",
      "+---------+-------+--------------------+--------+----------+------+------+-----------------+----+\n",
      "|pantallas|samsung|aparatos electron...|114999.0|2018-03-16|puebla|puebla|electrodomesticos|2018|\n",
      "+---------+-------+--------------------+--------+----------+------+------+-----------------+----+"
     ]
    }
   ],
   "source": [
    "# Obtener la fila con el precio máximo en el DataFrame\n",
    "# Se ordena el DataFrame por la columna \"precio\" en orden descendente y se selecciona la primera fila.\n",
    "# Esto permite identificar el producto con el precio más alto en los datos.\n",
    "\n",
    "df_max_precio = df.orderBy(col(\"precio\").desc()).limit(1)\n",
    "\n",
    "# Mostrar los resultados\n",
    "# Se imprime la fila con el precio máximo, incluyendo todas las columnas relevantes.\n",
    "df_max_precio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b7770",
   "metadata": {},
   "source": [
    "**Respuesta:** La marca con mayor precio es una pantallas de samsung por 114999.0 MXN. Se venio en el estado de Puebla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf8e59",
   "metadata": {},
   "source": [
    "¿Cuál es la marca con menor precio en CDMX? (en aquel entonces Distrito Federal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fb447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaulipas\n",
      "zacatecas\n",
      "nuevo leon\n",
      "campeche\n",
      "san luis potosi\n",
      "veracruz\n",
      "morelos\n",
      "guanajuato\n",
      "sonora\n",
      "tlaxcala\n",
      "nayarit\n",
      "sinaloa\n",
      "oaxaca\n",
      "guerrero\n",
      "quintana roo\n",
      "queretaro\n",
      "estado de mexico\n",
      "puebla\n",
      "durango\n",
      "jalisco\n",
      "aguascalientes\n",
      "coahuila de zaragoza\n",
      "baja california sur\n",
      "colima\n",
      "tabasco\n",
      "chihuahua\n",
      "baja california\n",
      "ciudad de mexico\n",
      "yucatan\n",
      "chiapas\n",
      "hidalgo\n",
      "michoacan de ocampo"
     ]
    }
   ],
   "source": [
    "# Obtener y mostrar los valores únicos de la columna \"estado\"\n",
    "# Este código selecciona los valores únicos de la columna \"estado\" en el DataFrame `df`.\n",
    "# Luego, utiliza `collect()` para convertir los resultados en una lista de filas.\n",
    "# Finalmente, itera sobre cada fila y muestra el valor de la columna \"estado\".\n",
    "\n",
    "unique_values = df.select(\"estado\").distinct().collect()\n",
    "for row in unique_values:\n",
    "    print(row[\"estado\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6643e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------------+------+----------+----------------+----------+----------------+----+\n",
      "|        producto|marca|            tipo|precio|     fecha|          estado|    ciudad|        catalogo|anio|\n",
      "+----------------+-----+----------------+------+----------+----------------+----------+----------------+----+\n",
      "|pliegos de papel|  s/m|material escolar|  0.87|2018-08-21|ciudad de mexico|iztapalapa|utiles escolares|2018|\n",
      "+----------------+-----+----------------+------+----------+----------------+----------+----------------+----+"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para obtener únicamente los datos de la Ciudad de México\n",
    "# Se seleccionan las filas donde la columna \"estado\" tiene el valor \"ciudad de mexico\".\n",
    "df_cdmx = df.filter(df['estado'] == 'ciudad de mexico')\n",
    "\n",
    "# Obtener la fila con el menor precio en la Ciudad de México\n",
    "# Se ordena el DataFrame por la columna \"precio\" en orden ascendente y se selecciona la primera fila.\n",
    "df_cdmx_menor_precio_cdmx = df_cdmx.orderBy(col(\"precio\").asc()).limit(1)\n",
    "\n",
    "# Mostrar los resultados\n",
    "# Se imprime la fila con el menor precio, incluyendo todas las columnas relevantes.\n",
    "df_cdmx_menor_precio_cdmx.show()\n",
    "\n",
    "# Guardar la salida en S3\n",
    "# Los resultados se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "s3_path_marca_menor_prec = f\"{BUCKET}/{FOLDER}/marca_menor_prec/\"\n",
    "df_cdmx_menor_precio_cdmx.write.mode(\"overwrite\").parquet(s3_path_marca_menor_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31365e",
   "metadata": {},
   "source": [
    "**Respuesta:** La marca de menor precio en CDMX es s/m con el procuto pliegos de papel por 0.87 MXN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c0b23",
   "metadata": {},
   "source": [
    "¿Cuál es la marca con mayores observaciones?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04c62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|producto|  count|\n",
      "+--------+-------+\n",
      "|refresco|2074163|\n",
      "+--------+-------+\n",
      "\n",
      "+-----+-------+\n",
      "|marca|  count|\n",
      "+-----+-------+\n",
      "|  s/m|2762039|\n",
      "+-----+-------+"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame por el catálogo \"basicos\"\n",
    "# Se seleccionan únicamente las filas donde la columna \"catalogo\" tiene el valor \"basicos\".\n",
    "df_filtered_by_cat = df.filter(df['catalogo'] == 'basicos')\n",
    "\n",
    "# Obtener el producto más frecuente en el catálogo \"basicos\"\n",
    "# Agrupamos los datos por la columna \"producto\" y contamos el número de observaciones por producto.\n",
    "# Luego, ordenamos los resultados en orden descendente por el conteo y seleccionamos el producto más frecuente.\n",
    "df_producto_mas_frecuente = df_filtered_by_cat.groupBy(\"producto\").count().orderBy(col(\"count\").desc()).limit(1)\n",
    "\n",
    "# Mostrar los resultados en la consola\n",
    "# Se imprime el producto más frecuente en el catálogo \"basicos\".\n",
    "df_producto_mas_frecuente.show()\n",
    "\n",
    "# Guardar el producto más frecuente en S3\n",
    "# Los resultados se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "s3_path_producto_mas_freq = f\"{BUCKET}/{FOLDER}/producto_mas_freq/\"\n",
    "df_producto_mas_frecuente.write.mode(\"overwrite\") \\\n",
    "                        .partitionBy(\"producto\") \\\n",
    "                        .option(\"compression\", \"snappy\") \\\n",
    "                        .parquet(s3_path_producto_mas_freq)\n",
    "\n",
    "# Obtener la marca más frecuente en el catálogo \"basicos\"\n",
    "# Agrupamos los datos por la columna \"marca\" y contamos el número de observaciones por marca.\n",
    "# Luego, ordenamos los resultados en orden descendente por el conteo y seleccionamos la marca más frecuente.\n",
    "df_marca_mas_frecuente = df_filtered_by_cat.groupBy(\"marca\").count().orderBy(col(\"count\").desc()).limit(1)\n",
    "\n",
    "# Mostrar los resultados en la consola\n",
    "# Se imprime la marca más frecuente en el catálogo \"basicos\".\n",
    "df_marca_mas_frecuente.show()\n",
    "\n",
    "# Guardar la marca más frecuente en S3\n",
    "# Los resultados se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "s3_path_marca_mas_freq = f\"{BUCKET}/{FOLDER}/marca_mas_freq/\"\n",
    "df_marca_mas_frecuente.write.mode(\"overwrite\") \\\n",
    "                        .partitionBy(\"marca\") \\\n",
    "                        .option(\"compression\", \"snappy\") \\\n",
    "                        .parquet(s3_path_marca_mas_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b4c966",
   "metadata": {},
   "source": [
    "**Respuesta:** La marca con mayores  observaciones es *s/m* con un total de 2762039 observaciones. Si lo vemos por producto, la mayor observaciones tiene *refrescos* con 2074163."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d77643",
   "metadata": {},
   "source": [
    "¿Cuáles son el top 5 de marcas con mayor precio en cada estado? ¿Son diferentes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4ccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+----------+\n",
      "|             estado|       marca|max_precio|\n",
      "+-------------------+------------+----------+\n",
      "|     aguascalientes|sony. bravia|   95272.0|\n",
      "|     aguascalientes|sony. bravia|   95236.0|\n",
      "|     aguascalientes|sony. bravia|   95216.0|\n",
      "|     aguascalientes|sony. bravia|   95116.0|\n",
      "|     aguascalientes|sony. bravia|   95111.0|\n",
      "|    baja california|     samsung|   68499.0|\n",
      "|    baja california|     samsung|   64999.0|\n",
      "|    baja california|     hisense|   55499.0|\n",
      "|    baja california|sony. bravia|   53570.0|\n",
      "|    baja california|     samsung|   51999.2|\n",
      "|baja california sur|          lg|   69999.0|\n",
      "|baja california sur|     samsung|   67149.0|\n",
      "|baja california sur|          lg|   66099.0|\n",
      "|baja california sur|     hisense|   55499.0|\n",
      "|baja california sur|     samsung|   52856.0|\n",
      "|           campeche|     samsung|  84125.56|\n",
      "|           campeche|     samsung|   64442.0|\n",
      "|           campeche|     samsung|   61999.0|\n",
      "|           campeche|          lg|   57140.0|\n",
      "|           campeche|          lg|   55553.0|\n",
      "+-------------------+------------+----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, row_number\n",
    "\n",
    "# Calcular el precio máximo por marca y estado\n",
    "# Agrupamos los datos por \"estado\", \"marca\" y \"precio\", y seleccionamos el precio como \"max_precio\".\n",
    "# Esto nos permite identificar el precio máximo de cada marca en cada estado.\n",
    "df_precio_por_marca_estado = df.groupBy(\"estado\", \"marca\", \"precio\").agg(col(\"precio\").alias(\"max_precio\"))\n",
    "\n",
    "# Aplicar ventana para obtener el top 5 de marcas con mayor precio por estado\n",
    "# Definimos una ventana particionada por \"estado\" y ordenada por \"max_precio\" en orden descendente.\n",
    "# Luego, asignamos un número de fila a cada registro dentro de cada partición utilizando `row_number()`.\n",
    "# Filtramos los registros para quedarnos únicamente con las 5 marcas con mayor precio por estado.\n",
    "window_spec = Window.partitionBy(\"estado\").orderBy(col(\"max_precio\").desc())\n",
    "df_top5 = df_precio_por_marca_estado.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar resultados\n",
    "# Seleccionamos las columnas \"estado\", \"marca\" y \"max_precio\" del DataFrame resultante y mostramos los resultados.\n",
    "df_top5.select(\"estado\", \"marca\", \"max_precio\").show()\n",
    "\n",
    "# Guardar la salida en S3\n",
    "# Guardamos los resultados en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "# Los datos se particionan por \"estado\" y \"marca\" para facilitar consultas posteriores.\n",
    "s3_path_5Top_marcas = f\"{BUCKET}/{FOLDER}/5Top_marcas/\"\n",
    "df_top5.select(\"estado\", \"marca\", \"max_precio\").write.mode(\"overwrite\")\\\n",
    "                        .partitionBy(\"estado\", \"marca\") \\\n",
    "                        .option(\"compression\", \"snappy\")\\\n",
    "                        .parquet(s3_path_5Top_marcas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9aee9d",
   "metadata": {},
   "source": [
    "**Respuesta:** Las top 5 de marcas con mayor precio en cada estado son diferentes (Sony, Samsung, Hisense, LG, etc. ) pero todos tienen en común que son electrodomesticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27a77e",
   "metadata": {},
   "source": [
    "¿Cuáles son el top 5 de marcas con menor precio en CDMX? (en aquel entonces Distrito Federal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------+\n",
      "|          producto|          estado|precio|\n",
      "+------------------+----------------+------+\n",
      "|  pliegos de papel|ciudad de mexico|  0.87|\n",
      "|  pliegos de papel|ciudad de mexico|  0.97|\n",
      "|  pliegos de papel|ciudad de mexico|   1.0|\n",
      "|pan blanco bolillo|ciudad de mexico|   1.0|\n",
      "|  pliegos de papel|ciudad de mexico|   1.0|\n",
      "+------------------+----------------+------+\n",
      "\n",
      "+-----+----------------+------+\n",
      "|marca|          estado|precio|\n",
      "+-----+----------------+------+\n",
      "|  s/m|ciudad de mexico|  0.87|\n",
      "|  s/m|ciudad de mexico|  0.97|\n",
      "|  s/m|ciudad de mexico|   1.0|\n",
      "|  s/m|ciudad de mexico|   1.0|\n",
      "|  s/m|ciudad de mexico|   1.0|\n",
      "+-----+----------------+------+"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para obtener únicamente los datos de la Ciudad de México\n",
    "# Se seleccionan las filas donde la columna \"estado\" tiene el valor \"ciudad de mexico\".\n",
    "df_cdmx = df.filter(df['estado'] == 'ciudad de mexico')\n",
    "\n",
    "# Definir una ventana para ordenar por precio ascendente\n",
    "# La ventana no tiene partición, ya que se busca el top 5 de productos con menor precio en toda la Ciudad de México.\n",
    "window_spec = Window.orderBy(col(\"precio\").asc())\n",
    "\n",
    "# Calcular el top 5 de productos con menor precio en la Ciudad de México\n",
    "# Se utiliza la función `row_number()` para asignar un rango a cada fila basado en el precio ascendente.\n",
    "# Luego, se filtran las filas para quedarse únicamente con las 5 primeras.\n",
    "df_top5_cdmx = df_cdmx.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar los resultados del top 5 de productos con menor precio\n",
    "# Se seleccionan las columnas \"producto\", \"estado\" y \"precio\" para mostrar los resultados.\n",
    "df_top5_cdmx.select(\"producto\", \"estado\", \"precio\").show()\n",
    "\n",
    "# Guardar los resultados del top 5 de productos con menor precio en S3\n",
    "# Los datos se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "# Se particionan por \"producto\" para facilitar consultas posteriores.\n",
    "s3_path_5Top_prod_menor_prec = f\"{BUCKET}/{FOLDER}/5Top_prod_menor_prec/\"\n",
    "df_top5_cdmx.select(\"producto\", \"estado\", \"precio\").write.mode(\"overwrite\") \\\n",
    "                        .partitionBy(\"producto\") \\\n",
    "                        .option(\"compression\", \"snappy\") \\\n",
    "                        .parquet(s3_path_5Top_prod_menor_prec)\n",
    "\n",
    "# Mostrar los resultados del top 5 de marcas con menor precio\n",
    "# Se seleccionan las columnas \"marca\", \"estado\" y \"precio\" para mostrar los resultados.\n",
    "df_top5_cdmx.select(\"marca\", \"estado\", \"precio\").show()\n",
    "\n",
    "# Guardar los resultados del top 5 de marcas con menor precio en S3\n",
    "# Los datos se guardan en formato Parquet en la ruta especificada en el bucket de S3.\n",
    "# Se particionan por \"marca\" para facilitar consultas posteriores.\n",
    "s3_path_5Top_marcas_menor_prec = f\"{BUCKET}/{FOLDER}/5Top_marcas_menor_prec/\"\n",
    "df_top5_cdmx.select(\"marca\", \"estado\", \"precio\").write.mode(\"overwrite\") \\\n",
    "                        .partitionBy(\"marca\") \\\n",
    "                        .option(\"compression\", \"snappy\") \\\n",
    "                        .parquet(s3_path_5Top_marcas_menor_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ed036",
   "metadata": {},
   "source": [
    "**Respuesta:** Las marcas con menor precio en CDMX son *s/m*, el tipo de producto son pliego papel y pan blanco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21610188",
   "metadata": {},
   "source": [
    "¿Cuáles son el top 5 de marcas con mayores observaciones? ¿Se parecen a las de nivel por estado?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+------+-----+\n",
      "|marca|          estado|precio|count|\n",
      "+-----+----------------+------+-----+\n",
      "|  s/m|ciudad de mexico|  29.9|42847|\n",
      "|  s/m|ciudad de mexico|  39.9|37643|\n",
      "|  s/m|ciudad de mexico|  20.0|37178|\n",
      "|  s/m|ciudad de mexico|  19.9|35388|\n",
      "|  s/m|ciudad de mexico|  99.0|35107|\n",
      "+-----+----------------+------+-----+\n",
      "\n",
      "+--------+----------------+------+-----+\n",
      "|producto|          estado|precio|count|\n",
      "+--------+----------------+------+-----+\n",
      "|refresco|ciudad de mexico|  22.0|29282|\n",
      "|refresco|ciudad de mexico|  13.0|25663|\n",
      "|refresco|ciudad de mexico|  25.0|22045|\n",
      "|refresco|ciudad de mexico|  14.0|21041|\n",
      "|refresco|ciudad de mexico|  23.0|17621|\n",
      "+--------+----------------+------+-----+"
     ]
    }
   ],
   "source": [
    "# Obtener el conteo de observaciones por marca\n",
    "# Agrupamos los datos por \"marca\", \"estado\" y \"precio\", y contamos el número de observaciones para cada combinación.\n",
    "# Luego, ordenamos los resultados en orden descendente por el conteo y seleccionamos las 5 marcas con más observaciones.\n",
    "df_top5_global = df.groupBy(\"marca\", \"estado\", \"precio\").count().orderBy(col(\"count\").desc()).limit(5)\n",
    "\n",
    "# Mostrar los resultados en la consola\n",
    "# Se imprimen las 5 marcas con más observaciones, incluyendo el estado y el precio asociado.\n",
    "df_top5_global.show()\n",
    "\n",
    "# Obtener el conteo de observaciones por producto\n",
    "# Agrupamos los datos por \"producto\", \"estado\" y \"precio\", y contamos el número de observaciones para cada combinación.\n",
    "# Luego, ordenamos los resultados en orden descendente por el conteo y seleccionamos los 5 productos con más observaciones.\n",
    "df_top5_global_p = df.groupBy(\"producto\", \"estado\", \"precio\").count().orderBy(col(\"count\").desc()).limit(5)\n",
    "\n",
    "# Mostrar los resultados en la consola\n",
    "# Se imprimen los 5 productos con más observaciones, incluyendo el estado y el precio asociado.\n",
    "df_top5_global_p.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91c000",
   "metadata": {},
   "source": [
    "**Respuesta:** Los top 5 de marcas con mayores observaciones *s/m*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b493e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardar la salida en S3 (marca)\n",
    "# Los resultados del top 5 de marcas con mayores observaciones se guardan en formato Parquet\n",
    "# en la ruta especificada en el bucket de S3. Esto permite realizar análisis posteriores.\n",
    "s3_path_5Top_marca_may_obs = f\"{BUCKET}/{FOLDER}/5Top_marca_may_obs/\"\n",
    "df_top5_global.select(\"marca\", \"estado\", \"precio\").write.mode(\"overwrite\").parquet(s3_path_5Top_marca_may_obs)\n",
    "\n",
    "# Guardar la salida en S3 (producto)\n",
    "# Los resultados del top 5 de productos con mayores observaciones se guardan en formato Parquet\n",
    "# en la ruta especificada en el bucket de S3. Esto facilita consultas y análisis futuros.\n",
    "s3_path_5Top_prod_may_obs = f\"{BUCKET}/{FOLDER}/5Top_prod_may_obs/\"\n",
    "df_top5_global_p.select(\"producto\", \"estado\", \"precio\").write.mode(\"overwrite\").parquet(s3_path_5Top_prod_may_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d7d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+------+----+\n",
      "|             estado|     marca| count|rank|\n",
      "+-------------------+----------+------+----+\n",
      "|     aguascalientes|       s/m|597475|   1|\n",
      "|     aguascalientes|       fud| 22276|   2|\n",
      "|     aguascalientes|      mabe| 21556|   3|\n",
      "|     aguascalientes|la costena| 21339|   4|\n",
      "|     aguascalientes|     oster| 21129|   5|\n",
      "|    baja california|       s/m|547912|   1|\n",
      "|    baja california|      mabe| 22652|   2|\n",
      "|    baja california|la costena| 22089|   3|\n",
      "|    baja california|        lg| 19075|   4|\n",
      "|    baja california|     oster| 16903|   5|\n",
      "|baja california sur|       s/m|459203|   1|\n",
      "|baja california sur|la costena| 23029|   2|\n",
      "|baja california sur|      mabe| 19660|   3|\n",
      "|baja california sur|     oster| 19280|   4|\n",
      "|baja california sur|        lg| 19147|   5|\n",
      "|           campeche|       s/m|581089|   1|\n",
      "|           campeche|       fud| 25016|   2|\n",
      "|           campeche|la costena| 24938|   3|\n",
      "|           campeche|     oster| 23681|   4|\n",
      "|           campeche|      mabe| 23225|   5|\n",
      "+-------------------+----------+------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----------------+-----+----+\n",
      "|             estado|         producto|count|rank|\n",
      "+-------------------+-----------------+-----+----+\n",
      "|     aguascalientes|         refresco|31511|   1|\n",
      "|     aguascalientes|            jamon|25160|   2|\n",
      "|     aguascalientes|          shampoo|23098|   3|\n",
      "|     aguascalientes|        carne res|22252|   4|\n",
      "|     aguascalientes|        pantallas|21671|   5|\n",
      "|    baja california|         refresco|42042|   1|\n",
      "|    baja california|          shampoo|22415|   2|\n",
      "|    baja california|        pantallas|19099|   3|\n",
      "|    baja california|detergente p/ropa|18414|   4|\n",
      "|    baja california|      desodorante|18164|   5|\n",
      "|baja california sur|         refresco|38000|   1|\n",
      "|baja california sur|          shampoo|21361|   2|\n",
      "|baja california sur|  toalla femenina|19823|   3|\n",
      "|baja california sur|            jamon|19776|   4|\n",
      "|baja california sur|        carne res|18903|   5|\n",
      "|           campeche|         refresco|34500|   1|\n",
      "|           campeche|            jamon|27928|   2|\n",
      "|           campeche|  toalla femenina|23614|   3|\n",
      "|           campeche|          shampoo|23158|   4|\n",
      "|           campeche|      desodorante|20551|   5|\n",
      "+-------------------+-----------------+-----+----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# Aplicar ventana para obtener el top 5 de marcas con mayores observaciones por estado\n",
    "# Definimos una ventana particionada por \"estado\" y ordenada por el conteo de observaciones en orden descendente.\n",
    "# Esto permite asignar un rango a cada marca dentro de cada estado basado en el número de observaciones.\n",
    "window_spec = Window.partitionBy(\"estado\").orderBy(col(\"count\").desc())\n",
    "\n",
    "# Calcular el top 5 de marcas con mayores observaciones por estado\n",
    "# Agrupamos los datos por \"estado\" y \"marca\", contamos el número de observaciones por cada combinación,\n",
    "# y aplicamos la ventana definida anteriormente para asignar un rango a cada marca.\n",
    "# Luego, filtramos las filas para quedarnos únicamente con las 5 marcas con más observaciones por estado.\n",
    "df_top5_estado = df.groupBy(\"estado\", \"marca\").count() \\\n",
    "    .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar los resultados del top 5 de marcas con mayores observaciones por estado\n",
    "df_top5_estado.show()\n",
    "\n",
    "# Aplicar ventana para obtener el top 5 de productos con mayores observaciones por estado\n",
    "# Similar al cálculo anterior, pero agrupamos los datos por \"estado\" y \"producto\" en lugar de \"marca\".\n",
    "df_top5_estado_p = df.groupBy(\"estado\", \"producto\").count() \\\n",
    "    .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "    .filter(col(\"rank\") <= 5)\n",
    "\n",
    "# Mostrar los resultados del top 5 de productos con mayores observaciones por estado\n",
    "df_top5_estado_p.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74679bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardar la salida en S3 (marca)\n",
    "s3_path_5Top_marca_may_obs_estado = f\"{BUCKET}/{FOLDER}/5Top_marca_may_obs_estado/\"\n",
    "df_top5_global.select(\"marca\", \"estado\", \"precio\").write.mode(\"overwrite\")\\\n",
    "                    .partitionBy(\"estado\", \"marca\")\\\n",
    "                    .option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(s3_path_5Top_marca_may_obs_estado)\n",
    "\n",
    "# Guardar la salida en S3 (producto)\n",
    "s3_path_5Top_prod_may_obs_estado = f\"{BUCKET}/{FOLDER}/5Top_prod_may_obs_estado/\"\n",
    "df_top5_global_p.select(\"producto\", \"estado\", \"precio\").write.mode(\"overwrite\")\\\n",
    "                    .partitionBy(\"estado\", \"producto\")\\\n",
    "                    .option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(s3_path_5Top_prod_may_obs_estado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f78b4b",
   "metadata": {},
   "source": [
    " ¿Se parecen a las de nivel por estado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0e967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------------------------------+\n",
      "|estado              |top_5_marcas                                  |\n",
      "+--------------------+----------------------------------------------+\n",
      "|aguascalientes      |[s/m, fud, mabe, la costena, oster]           |\n",
      "|baja california     |[s/m, mabe, la costena, lg, oster]            |\n",
      "|baja california sur |[s/m, la costena, mabe, oster, lg]            |\n",
      "|campeche            |[s/m, fud, la costena, oster, mabe]           |\n",
      "|chiapas             |[s/m, la costena, mabe, oster, bimbo]         |\n",
      "|chihuahua           |[s/m, la costena, mabe, lg, bimbo]            |\n",
      "|ciudad de mexico    |[s/m, la costena, fud, bimbo, lala]           |\n",
      "|coahuila de zaragoza|[s/m, la costena, mabe, fud, lg]              |\n",
      "|colima              |[s/m, la costena, lg, fud, mabe]              |\n",
      "|durango             |[s/m, oster, lg, la costena, mabe]            |\n",
      "|estado de mexico    |[s/m, la costena, fud, bimbo, lala]           |\n",
      "|guanajuato          |[s/m, la costena, oster, fud, mabe]           |\n",
      "|guerrero            |[s/m, la costena, oster, lg, fud]             |\n",
      "|hidalgo             |[s/m, la costena, mabe, oster, lg]            |\n",
      "|jalisco             |[s/m, la costena, fud, oster, mabe]           |\n",
      "|michoacan de ocampo |[s/m, la costena, fud, mabe, lg]              |\n",
      "|morelos             |[s/m, la costena, fud, mabe, clemente jacques]|\n",
      "|nayarit             |[s/m, la costena, fud, mabe, lg]              |\n",
      "|nuevo leon          |[s/m, la costena, fud, oster, bimbo]          |\n",
      "|oaxaca              |[s/m, la costena, mabe, oster, fud]           |\n",
      "+--------------------+----------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+----------------------------------------------------------------------+\n",
      "|estado              |top_5_productos                                                       |\n",
      "+--------------------+----------------------------------------------------------------------+\n",
      "|aguascalientes      |[refresco, jamon, shampoo, carne res, pantallas]                      |\n",
      "|baja california     |[refresco, shampoo, pantallas, detergente p/ropa, desodorante]        |\n",
      "|baja california sur |[refresco, shampoo, toalla femenina, jamon, carne res]                |\n",
      "|campeche            |[refresco, jamon, toalla femenina, shampoo, desodorante]              |\n",
      "|chiapas             |[refresco, carne res, shampoo, pantallas, detergente p/ropa]          |\n",
      "|chihuahua           |[refresco, shampoo, pantallas, detergente p/ropa, desodorante]        |\n",
      "|ciudad de mexico    |[refresco, jamon, shampoo, desodorante, toalla femenina]              |\n",
      "|coahuila de zaragoza|[refresco, shampoo, jamon, carne res, pantallas]                      |\n",
      "|colima              |[refresco, shampoo, pantallas, detergente p/ropa, desodorante]        |\n",
      "|durango             |[refresco, shampoo, pantallas, jamon, detergente p/ropa]              |\n",
      "|estado de mexico    |[refresco, jamon, shampoo, desodorante, toalla femenina]              |\n",
      "|guanajuato          |[refresco, jamon, shampoo, desodorante, toalla femenina]              |\n",
      "|guerrero            |[refresco, shampoo, pantallas, jamon, jabon de tocador]               |\n",
      "|hidalgo             |[refresco, carne res, carne cerdo, pantallas, shampoo]                |\n",
      "|jalisco             |[refresco, jamon, leche ultrapasteurizada, detergente p/ropa, shampoo]|\n",
      "|michoacan de ocampo |[refresco, carne res, carne cerdo, jamon, shampoo]                    |\n",
      "|morelos             |[refresco, shampoo, jamon, carne res, carne cerdo]                    |\n",
      "|nayarit             |[refresco, shampoo, detergente p/ropa, carne res, carne cerdo]        |\n",
      "|nuevo leon          |[refresco, shampoo, jamon, toalla femenina, desodorante]              |\n",
      "|oaxaca              |[refresco, jamon, shampoo, desodorante, toalla femenina]              |\n",
      "+--------------------+----------------------------------------------------------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "# Obtener lista de marcas en el top global\n",
    "marcas_top_global = [row[\"marca\"] for row in df_top5_global.collect()]\n",
    "\n",
    "# Agrupar marcas del top 5 por estado y compararlas con el top global\n",
    "df_comparacion = df_top5_estado.groupBy(\"estado\").agg(collect_list(\"marca\").alias(\"top_5_marcas\"))\n",
    "\n",
    "df_comparacion.show(truncate=False)\n",
    "\n",
    "# Guardar la salida en S3\n",
    "s3_path_5Top_marca_comparacion_estado = f\"{BUCKET}/{FOLDER}/5Top_marca_comparacion_estado/\"\n",
    "df_comparacion.write.mode(\"overwrite\")\\\n",
    "                    .partitionBy(\"estado\")\\\n",
    "                    .option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(s3_path_5Top_marca_comparacion_estado)\n",
    "\n",
    "\n",
    "# Obtener lista de marcas en el top global\n",
    "producto_top_global = [row[\"producto\"] for row in df_top5_global_p.collect()]\n",
    "\n",
    "# Agrupar marcas del top 5 por estado y compararlas con el top global\n",
    "df_comparacion_p = df_top5_estado_p.groupBy(\"estado\").agg(collect_list(\"producto\").alias(\"top_5_productos\"))\n",
    "\n",
    "df_comparacion_p.show(truncate=False)\n",
    "\n",
    "# Guardar la salida en S3\n",
    "s3_path_5Top_prod_comparacion_estado = f\"{BUCKET}/{FOLDER}/5Top_prod_comparacion_estado/\"\n",
    "df_comparacion_p.write.mode(\"overwrite\")\\\n",
    "                    .partitionBy(\"estado\")\\\n",
    "                    .option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(s3_path_5Top_prod_comparacion_estado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0b628",
   "metadata": {},
   "source": [
    "¿Ha dejado de existir alguna marca durante los años que tienes? ¿Cuál? ¿Cuándo desapareció?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492963c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               marca|ultimo_anio|\n",
      "+--------------------+-----------+\n",
      "|             kleenex|       2023|\n",
      "|osram. dulux el m...|       2023|\n",
      "|kleenex. cottonel...|       2022|\n",
      "|             lyncott|       2023|\n",
      "|osram. dulux valu...|       2023|\n",
      "|        alpura. kids|       2022|\n",
      "|colgate. luminous...|       2021|\n",
      "|    alpura. vaquitas|       2022|\n",
      "|  petalo. ultra care|       2022|\n",
      "|         mundet lift|       2021|\n",
      "|quality day. led ...|       2023|\n",
      "| savile. hidratacion|       2021|\n",
      "|            frutimax|       2023|\n",
      "|l oreal. paris. c...|       2021|\n",
      "|colgate. luminous...|       2023|\n",
      "|    oral-b. 3d white|       2021|\n",
      "|gran cosecha. pre...|       2023|\n",
      "|oral-b. 3d white....|       2023|\n",
      "|soriana. espiral....|       2021|\n",
      "|svelty. con colag...|       2023|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtener marcas únicas por año\n",
    "df_marcas_por_anio = df.select(\"anio\", \"marca\").distinct()\n",
    "\n",
    "# Obtener todas las marcas que existieron alguna vez\n",
    "marcas_existentes = df_marcas_por_anio.select(\"marca\").distinct()\n",
    "\n",
    "# Obtener la última aparición de cada marca\n",
    "df_ultima_aparicion = df_marcas_por_anio.groupBy(\"marca\").agg({\"anio\": \"max\"}).withColumnRenamed(\"max(anio)\", \"ultimo_anio\")\n",
    "\n",
    "# Comparar con las marcas actuales (último año presente en los datos)\n",
    "ultimo_anio = df.select(\"anio\").distinct().orderBy(\"anio\", ascending=False).limit(1).collect()[0][\"anio\"]\n",
    "df_marcas_desaparecidas = df_ultima_aparicion.filter(df_ultima_aparicion[\"ultimo_anio\"] < ultimo_anio)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_marcas_desaparecidas.show()\n",
    "\n",
    "# Guardar la salida en S3\n",
    "s3_path_marcas_deaparecidas = f\"{BUCKET}/{FOLDER}/marcas_deaparecidas/\"\n",
    "df_marcas_desaparecidas.write.mode(\"overwrite\")\\\n",
    "                    .partitionBy(\"marca\")\\\n",
    "                    .option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(s3_path_marcas_deaparecidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1af69",
   "metadata": {},
   "source": [
    "Genera una gráfica de serie de tiempo por estado para la marca con mayor precio -en todos los años-, donde el eje equis es el año y el eje ye es el precio máximo.\n",
    "Nota: Recuerden descargar del cluster su análisis en Jupyter, de otra manera se borrará.\n",
    "\n",
    "Hint: Guarda tus consultas en archivos que puedas guardar en S3 y luego leer desde Pandas o RStudio, para hacer tus gráficas o cuadros compartivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac14f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas) (2025.1)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.13.0)\n",
      "Installing collected packages: tzdata, python-dateutil, numpy, pandas\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Not uninstalling python-dateutil at /usr/lib/python3.9/site-packages, outside environment /mnt/yarn/usercache/livy/appcache/application_1746393038637_0002/container_1746393038637_0002_01_000001/tmp/spark-8cc307e1-a7f7-4fd7-aea3-111a06d1dce8\n",
      "    Can't uninstall 'python-dateutil'. No files were found to uninstall.\n",
      "Successfully installed numpy-2.0.2 pandas-2.2.3 python-dateutil-2.9.0.post0 tzdata-2025.2\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 2.23.11 requires python-dateutil<=2.9.0,>=2.1, but you have python-dateutil 2.9.0.post0 which is incompatible."
     ]
    }
   ],
   "source": [
    "spark._sc.install_pypi_package(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24f668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./tmp/spark-8cc307e1-a7f7-4fd7-aea3-111a06d1dce8/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./tmp/spark-8cc307e1-a7f7-4fd7-aea3-111a06d1dce8/lib64/python3.9/site-packages (from matplotlib) (2.0.2)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.2.1-cp39-cp39-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.13.0)\n",
      "Installing collected packages: zipp, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.57.0 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 pillow-11.2.1 zipp-3.21.0\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag."
     ]
    }
   ],
   "source": [
    "spark._sc.install_pypi_package(\"matplotlib\", \"https://pypi.org/simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c5843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\",\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d6b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2d07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "[PATH_NOT_FOUND] Path does not exist: hdfs://ip-172-31-5-244.ec2.internal:8020/user/livy/tbd.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1746393038637_0002/container_1746393038637_0002_01_000001/pyspark.zip/pyspark/sql/readwriter.py\", line 544, in parquet\n",
      "    return self._df(self._jreader.parquet(_to_seq(self._spark._sc, paths)))\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1746393038637_0002/container_1746393038637_0002_01_000001/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1746393038637_0002/container_1746393038637_0002_01_000001/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: hdfs://ip-172-31-5-244.ec2.internal:8020/user/livy/tbd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializar Spark Session\n",
    "spark = SparkSession.builder.appName(\"Time Series Analysis\").getOrCreate()\n",
    "\n",
    "# Cargar datos desde S3\n",
    "df = spark.read.parquet(\"tbd\")\n",
    "\n",
    "# Obtener la marca con el mayor precio en todos los años\n",
    "df_max_precio_marca = df.groupBy(\"estado\", \"anio\", \"marca\").agg(col(\"precio\").alias(\"max_precio\")) \\\n",
    "    .orderBy(col(\"max_precio\").desc()).dropDuplicates([\"anio\", \"estado\"])\n",
    "\n",
    "# Convertir a Pandas para graficar\n",
    "df_pandas = df_max_precio_marca.toPandas()\n",
    "\n",
    "# Crear gráfica de serie de tiempo\n",
    "plt.figure(figsize=(12, 6))\n",
    "for estado in df_pandas[\"estado\"].unique():\n",
    "    data_estado = df_pandas[df_pandas[\"estado\"] == estado]\n",
    "    plt.plot(data_estado[\"anio\"], data_estado[\"max_precio\"], marker=\"o\", label=estado)\n",
    "\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Precio Máximo\")\n",
    "plt.title(\"Evolución del Precio Máximo por Estado (Marca Más Cara)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f89a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa96f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_path_df_complete = f\"{BUCKET}/{FOLDER}/df_complete/\"\n",
    "df.write.mode(\"overwrite\")\\\n",
    "                    .partitionBy(\"Estado\", \"anio\", \"catalogo\")\\\n",
    "                    .option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(s3_path_df_complete )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413f34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_basicos = df.filter(df['catalogo']=='basicos')\n",
    "s3_path_df_complete_basicos = f\"{BUCKET}/{FOLDER}/df_complete_basicos/\"\n",
    "df_basicos.write.mode(\"overwrite\")\\\n",
    "                    .partitionBy(\"Estado\", \"anio\",)\\\n",
    "                    .option(\"compression\", \"snappy\")\\\n",
    "                    .parquet(s3_path_df_complete_basicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b1d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arquitectura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "python3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
